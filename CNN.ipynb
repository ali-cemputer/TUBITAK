{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "tf.test.is_built_with_cuda() #GPU aktif mi?"
   ],
   "id": "1a79acbd07563f52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Build Info:\", tf.sysconfig.get_build_info())\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Bellek optimizasyonu (GPU kullanımı için)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Bellek büyümesini sınırla\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)#TensorFlow’un başlangıçta minimum bellek tahsis etmesini ve yalnızca gerektiğinde bellek kullanmasını sağlar.\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "ebc5754e90625a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Output konsol ayarlamaları\n",
    "pd.set_option('display.max_columns', None)# Tüm sütunları göster\n",
    "pd.set_option('display.max_rows', None)# Tüm satırları göster\n",
    "pd.set_option('display.max_colwidth', None)# Tüm sütun içeriğini gösterir.\n",
    "pd.set_option(\"display.float_format\", lambda x: '%.3f' % x)# ondalıklı sayıları 3 basamaklı şekilde kısaltır.\n",
    "pd.set_option('display.width', 5000)# DataFrame oto. alta geçmesin tek satırda gösterilsin diye. 5000 karakter hakkı vardır."
   ],
   "id": "31a82c0303724e5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "IMG_SIZE = (224, 224)   # Güncellenmiş boyut\n",
    "EPOCHS = 100 # Modelin veriyi kaç defa işleyecek\n",
    "ORIGINAL_DATA_PATH = \"../TUBITAK/datasets/CSV_Multi_Label_Classification\"\n",
    "AUGMENTED_DATA_PATH = \"../TUBITAK/datasets/CSV_Multi_Label_Classification_Augmented\""
   ],
   "id": "a7ac263981c50fc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Orijinal verileri yükle\n",
    "original_train_df = utils.load_data('train', base_path=ORIGINAL_DATA_PATH)\n",
    "original_valid_df = utils.load_data('valid', base_path=ORIGINAL_DATA_PATH)\n",
    "original_test_df = utils.load_data('test', base_path=ORIGINAL_DATA_PATH)\n",
    "\n",
    "print(\"\\nOrijinal Veri Seti Dağılımı:\")\n",
    "print(f\"Train set: {len(original_train_df)} images\")\n",
    "print(f\"Validation set: {len(original_valid_df)} images\")\n",
    "print(f\"Test set: {len(original_test_df)} images\")\n",
    "\n",
    "print(\"\\nOrijinal Eğitim Seti Etiket Dağılımı:\")\n",
    "print(\"Moderate Accident:\", original_train_df['moderate'].sum())\n",
    "print(\"Severe Accident:\", original_train_df['severe'].sum())\n",
    "print(\"No Accident:\", original_train_df['no_accident'].sum())\n",
    "print(\"Multi-label (Moderate & Severe):\", ((original_train_df['moderate'] == 1) & (original_train_df['severe'] == 1)).sum())"
   ],
   "id": "d1bb1cbf84f7cecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if not os.path.exists(os.path.join(AUGMENTED_DATA_PATH, 'train', '_classes.csv')):\n",
    "\n",
    "    # Veri artırımı uygula ve yeni klasöre kaydet\n",
    "    print(\"\\nVeriler artırılıyor ve yeni dizine kaydediliyor...\")\n",
    "    utils.augment_and_save_data(original_train_df, 'train',\n",
    "                                no_accident_aug_size=25, moderate_aug_size=1, severe_aug_size=0,\n",
    "                                output_base_path=AUGMENTED_DATA_PATH)\n",
    "    utils.augment_and_save_data(original_valid_df, 'valid',\n",
    "                                no_accident_aug_size=25, moderate_aug_size=1, severe_aug_size=0,\n",
    "                                output_base_path=AUGMENTED_DATA_PATH)\n",
    "    utils.augment_and_save_data(original_test_df, 'test',\n",
    "                                no_accident_aug_size=0, moderate_aug_size=0, severe_aug_size=0,\n",
    "                                output_base_path=AUGMENTED_DATA_PATH)\n",
    "else:\n",
    "    print(\"Artırılmış veri seti zaten mevcut, mevcut veriler kullanılıyor.\")\n",
    "\n",
    "\n",
    "# Artırılmış veri setini yükle\n",
    "train_df = utils.load_data('train', base_path=AUGMENTED_DATA_PATH)\n",
    "valid_df = utils.load_data('valid', base_path=AUGMENTED_DATA_PATH)\n",
    "test_df = utils.load_data('test', base_path=AUGMENTED_DATA_PATH)\n",
    "\n",
    "# Tensorflow Dataset'leri oluştur\n",
    "train_dataset = utils.create_dataset(train_df)\n",
    "valid_dataset = utils.create_dataset(valid_df)\n",
    "test_dataset = utils.create_dataset(test_df)\n",
    "\n",
    "print(f\"\\nGüncel Train set: {len(train_df)} images\")\n",
    "print(f\"Güncel Validation set: {len(valid_df)} images\")\n",
    "print(f\"Güncel Test set: {len(test_df)} images\")\n",
    "\n",
    "# Güncel etiket dağılımını kontrol et\n",
    "print(\"\\nGüncel Eğitim seti etiket dağılımı:\")\n",
    "print(\"Moderate Accident:\", train_df['moderate'].sum())\n",
    "print(\"Severe Accident:\", train_df['severe'].sum())\n",
    "print(\"No Accident:\", train_df['no_accident'].sum())\n",
    "print(\"Multi-label (Moderate & Severe):\", ((train_df['moderate'] == 1) & (train_df['severe'] == 1)).sum())"
   ],
   "id": "860a698cde63a062",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Model Mimarisi Oluşturma\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Trafik kazası sınıflandırması için Evrişimli Sinir Ağı (CNN) modelini oluşturur.\n",
    "    Dropout ve L2 regülarizasyon ile overfitting azaltılmıştır.\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # İlk Convolutional blok\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(0.002)), # L2 regülarizasyon\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # İkinci Convolutional blok\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(0.002)), # L2 regülarizasyon\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Üçüncü Convolutional blok\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same',\n",
    "                      kernel_regularizer=tf.keras.regularizers.l2(0.002)), # L2 regülarizasyon\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        # Sınıflandırma katmanları\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.6),\n",
    "        layers.Dense(3, activation='softmax') # class_names sayısına göre çıktı katmanı\n",
    "    ])\n",
    "\n",
    "    # Model derleme\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Model oluştur\n",
    "model = create_model()"
   ],
   "id": "aa441b24000ec12d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',#Doğrulama kaybını izle\n",
    "        patience=8,#x epoch boyunca iyileşme olmazsa dur\n",
    "        restore_best_weights=True# En iyi ağırlıklara geri dön\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',# Doğrulama kaybı durursa\n",
    "        factor=0.5,# Öğrenme oranını %x azalt\n",
    "        patience=3,# x epoch boyunca iyileşme olmazsa lr düşür\n",
    "        min_lr=1e-6 # En düşük learningrate oranı\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_cnn_model.h5\",\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,#en düşük val_loss olduğunda kaydet.\n",
    "        mode='min',\n",
    "    )\n",
    "]"
   ],
   "id": "71d404701fe05f4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#modeli eğit\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=my_callbacks,\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "4324f25cbe3b5eeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Eğitim sonuçlarını görselleştir\n",
    "plt.figure(figsize=(12, 4))#12X4 LÜK GRAFİK PENCERESİ OLUŞTUR.\n",
    "\n",
    "#Accuracy Greafiği\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Eğitim Doğruluğu')\n",
    "plt.plot(history.history['val_accuracy'], label='Doğrulama Doğruluğu')\n",
    "plt.title('Model Doğruluğu')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Doğruluk')\n",
    "plt.legend()\n",
    "\n",
    "#Loss grafiği\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Eğitim Kaybı')\n",
    "plt.plot(history.history['val_loss'], label='Doğrulama Kaybı')\n",
    "plt.title('Model Kaybı')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Kayıp')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "a2632a0d37d406d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_names = ['Moderate Accident', 'Severe Accident', 'No Accident']\n",
    "utils.evaluate_model(model, test_dataset, class_names)"
   ],
   "id": "3ade99a5d18ca801",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_image_paths = test_df['filename'].tolist()  # Test seti görüntü yolları\n",
    "# Tahminlerin görselleştirilmesi\n",
    "utils.visualize_predictions(\n",
    "    model=model,\n",
    "    image_paths=test_image_paths,\n",
    "    class_names=class_names,\n",
    "    num_images=5\n",
    ")"
   ],
   "id": "2f9c856658e9dcf1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
